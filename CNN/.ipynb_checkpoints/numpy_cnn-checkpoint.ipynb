{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5a6b81b-1270-4676-9574-e7ae48ac040a",
   "metadata": {},
   "source": [
    "使用numpy实现cnn并测试mnist手写识别\n",
    "网络架构为一层卷积层，一层最大池化层，一层打平层和两层全连接层\n",
    "inpit(1,28*28)=>conv(1,3,3)=>relu=>max pooling=>flatten=>fc(64)=>fc(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4fd17a4-7757-4d95-a451-3c26e818e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#权重初始化\n",
    "weights = {}\n",
    "weights_scale = 1e-2\n",
    "filters = 1\n",
    "fc_units = 64\n",
    "weights[\"k1\"] = weights_scale * np.random.randn(1, filters, 3 , 3).astype(np.float64)\n",
    "weights[\"b1\"] = np.zeros(filters).astype(np.float64)\n",
    "weights[\"w2\"] = weights_scale * np.random.randn(filters * 13 * 13, fc_units).astype(np.float64)\n",
    "weights[\"b2\"] = np.zeros(fc_units).astype(np.float64)\n",
    "weights[\"w3\"] = weights_scale * np.random.randn(fc_units, 10).astype(np.float64)\n",
    "weights[\"b3\"] = np.zeros(10).astype(np.float64)\n",
    "\n",
    "#初始化神经元和梯度\n",
    "nuerons = {}\n",
    "gradients = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "333d6869-e85d-49b0-89b6-e2e9a09a877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义前向传播和反向传播\n",
    "from nn.layers import conv_forward_bak, max_pooling_forward_bak, fc_forward, flatten_forward\n",
    "from nn.layers import conv_backward,max_pooling_backward_bak, fc_backward, flatten_backward\n",
    "from nn.activations import relu_forward,relu_backward\n",
    "from nn.losses import cross_entropy_loss\n",
    "\n",
    "#前向传播\n",
    "def forward(X):\n",
    "    nuerons[\"conv1\"] = conv_forward_bak(X.astype(np.float64), weights[\"k1\"], weights[\"b1\"])\n",
    "    nuerons[\"conv1_relu\"] = relu_forward(nuerons[\"conv1\"])\n",
    "    nuerons[\"maxp1\"] = max_pooling_forward_bak(nuerons[\"conv1_relu\"].astype(np.float64), pooling = (2, 2))\n",
    "\n",
    "    nuerons[\"flatten\"] = flatten_forward(nuerons[\"maxp1\"])\n",
    "    nuerons[\"fc2\"] = fc_forward(nuerons[\"flatten\"], weights[\"w2\"], weights[\"b2\"])\n",
    "    nuerons[\"fc2_relu\"] = relu_forward(nuerons[\"fc2\"])\n",
    "\n",
    "    nuerons[\"y\"] = fc_forward(nuerons[\"fc2_relu\"], weights[\"w3\"], weights[\"b3\"])\n",
    "    \n",
    "    return nuerons[\"y\"]\n",
    "\n",
    "#定义反向传播\n",
    "def backward(X, y_true):\n",
    "    loss, dy = cross_entropy_loss(nuerons[\"y\"], y_true)\n",
    "    gradients[\"w3\"], gradients[\"b3\"], gradients[\"fc2_relu\"] = fc_backward(dy, weights[\"w3\"], nuerons[\"fc2_relu\"])\n",
    "    gradients[\"fc2\"] = relu_backward(gradients[\"fc2_relu\"], nuerons[\"fc2\"])\n",
    "\n",
    "    gradients[\"w2\"], gradients[\"b2\"], gradients[\"flatten\"] = fc_backward(gradients[\"fc2\"], weights[\"w2\"], nuerons[\"flatten\"])\n",
    "    gradients[\"maxp1\"] = flatten_backward(gradients[\"flatten\"], nuerons[\"maxp1\"])\n",
    "\n",
    "    gradients[\"conv1_relu\"] = max_pooling_backward_bak(gradients[\"maxp1\"].astype(np.float64), nuerons[\"conv1_relu\"].astype(np.float64), pooling=(2, 2))\n",
    "    gradients[\"conv1\"] = relu_backward(gradients[\"conv1_relu\"], nuerons[\"conv1\"])\n",
    "    gradients[\"k1\"], gradients[\"b1\"], _ = conv_backward(gradients[\"conv1\"], weights[\"k1\"], X)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49ec389d-9832-47ae-b0d1-9e879650fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取准确率\n",
    "def get_accuracy(X, y_true):\n",
    "    y_predict = forward(X)\n",
    "    return np.mean(np.equal(np.argmax(y_predict, axis = -1), np.argmax(y_true, axis = -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f9c2fa1-6878-4a49-b182-edcb6cb7356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.load_mnist import load_mnist_datasets\n",
    "from nn.utils import to_categorical\n",
    "train_set, val_set, test_set = load_mnist_datasets('mnist.pkl.gz')\n",
    "train_x,val_x,test_x=np.reshape(train_set[0],(-1,1,28,28)),np.reshape(val_set[0],(-1,1,28,28)),np.reshape(test_set[0],(-1,1,28,28))\n",
    "train_y,val_y,test_y=to_categorical(train_set[1]),to_categorical(val_set[1]),to_categorical(test_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea053977-bed5-492c-9bd5-cd6bf615d022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x,shape:(16, 1, 28, 28), y.shape:(16, 10)\n"
     ]
    }
   ],
   "source": [
    "#随机选择训练样本\n",
    "train_num = train_x.shape[0]\n",
    "def next_batch(batch_size):\n",
    "    idx = np.random.choice(train_num, batch_size)\n",
    "    return train_x[idx], train_y[idx]\n",
    "\n",
    "x, y = next_batch(16)\n",
    "print(\"x,shape:{}, y.shape:{}\".format(x.shape, y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ccb32c-50ca-4ce7-aba3-14720ff37c30",
   "metadata": {},
   "source": [
    "开始训练，设置mini-batch为2,迭代2000步，总共训练4000个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16caa661-ba0f-4bbe-9f26-524019be2111",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m forward(X)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#反向\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m sgd\u001b[38;5;241m.\u001b[39miterate(weights, gradients)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[2], line 32\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(X, y_true)\u001b[0m\n\u001b[1;32m     30\u001b[0m gradients[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv1_relu\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m max_pooling_backward_bak(gradients[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaxp1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64), nuerons[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv1_relu\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64), pooling\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m     31\u001b[0m gradients[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m relu_backward(gradients[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv1_relu\u001b[39m\u001b[38;5;124m\"\u001b[39m], nuerons[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv1\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 32\u001b[0m gradients[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk1\u001b[39m\u001b[38;5;124m\"\u001b[39m], gradients[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb1\u001b[39m\u001b[38;5;124m\"\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[43mconv_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgradients\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconv1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mk1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/workspace/jupyter_data/nn/layers.py:132\u001b[0m, in \u001b[0;36mconv_backward\u001b[0;34m(next_dz, k, z, padding, strides)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m#零填充增加高度和宽度\u001b[39;00m\n\u001b[1;32m    130\u001b[0m padding_next_dz \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mpad(z, ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m),(k1 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, k1 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m),\\\n\u001b[1;32m    131\u001b[0m                              (k2 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, k2 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m, constant_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 132\u001b[0m dz \u001b[38;5;241m=\u001b[39m conv_forward_bak(padding_next_dz, swap_flip_k, np\u001b[38;5;241m.\u001b[39mzeros((C,), dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m))\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#求卷积和的梯度dk\u001b[39;00m\n\u001b[1;32m    135\u001b[0m swap_z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mswapaxes(z, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m#(C,N,H,W)\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/jupyter_venv/lib/python3.10/site-packages/numpy/__init__.py:324\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    319\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 324\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "from nn.optimizers import SGD\n",
    "batch_size = 2\n",
    "steps = 2000\n",
    "\n",
    "sgd = SGD(weights, lr=0.01, decay=1e-6)\n",
    "\n",
    "for s in range(steps):\n",
    "    X, y = next_batch(batch_size)\n",
    "\n",
    "    #前向\n",
    "    forward(X)\n",
    "    #反向\n",
    "    loss = backward(X, y)\n",
    "\n",
    "    sgd.iterate(weights, gradients)\n",
    "\n",
    "    if s % 100 == 0:\n",
    "        print(\"\\n step:{} ; loss:{}\".format(s, loss))\n",
    "        idx = np.random.choice(len(val_x), 200)\n",
    "        print(\" train_acc:{}; val_acc:{}\".format(get_accuracy(X, y), get_accuracy(val_x[idx], val_y[idx])))\n",
    "\n",
    "print(\"\\n final result test_acc:{}; val_acc:{}\".\n",
    "      format(get_accuracy(test_x, test_y), get_accuracy(val_x, val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b309e0-6252-40f1-b168-09f0e19f5406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_venv",
   "language": "python",
   "name": "jupyter_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
